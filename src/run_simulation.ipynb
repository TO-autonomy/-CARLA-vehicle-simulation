{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import queue\n",
    "from matplotlib import cm\n",
    "import shutil \n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import urdf_parser_py.urdf as urdf\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to CARLA server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10)\n",
    "world = client.get_world()\n",
    "map = world.get_map()\n",
    "\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_world():\n",
    "    global world, map, blueprint_library, spawn_points, traffic_manager\n",
    "    world = client.reload_world()\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "    traffic_manager = client.get_trafficmanager()\n",
    "\n",
    "def load_world(map_name=\"Town01\", timeout=10.0):\n",
    "    global world, map, blueprint_library, spawn_points, traffic_manager\n",
    "    client.set_timeout(timeout)\n",
    "    world = client.load_world(map_name)\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "    traffic_manager = client.get_trafficmanager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 5)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds,\n",
    "            ))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout):\n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read simulation configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(data_dict, keys, default=None):\n",
    "    for key in keys:\n",
    "        if isinstance(data_dict, dict):\n",
    "            data_dict = data_dict.get(key, default)\n",
    "        else:\n",
    "            return default\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_transform(matrix):\n",
    "    # Extract translation\n",
    "    location = carla.Location(x=matrix[0, 3], y=(-matrix[1, 3]), z=matrix[2, 3])\n",
    "\n",
    "    roll, pitch, yaw = Rotation.from_matrix(matrix[:3, :3]).as_euler('xyz', degrees=True)\n",
    "    rotation = carla.Rotation(pitch=(-pitch), yaw=(-yaw), roll=roll)\n",
    "    \n",
    "    # Create and return carla.Transform\n",
    "    return carla.Transform(location, rotation)\n",
    "\n",
    "\n",
    "def build_transform_matrix(rotation, translation):\n",
    "    m = np.eye(4)\n",
    "    m[:3, :3] = rotation\n",
    "    m[:3, 3] = translation\n",
    "    return m\n",
    "\n",
    "\n",
    "def rotation_matrix(axis, angle):\n",
    "    \"\"\"\n",
    "    Create a rotation matrix for a given axis and angle.\n",
    "    \"\"\"\n",
    "    if axis == 'x':\n",
    "        return np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, np.cos(angle), -np.sin(angle), 0],\n",
    "            [0, np.sin(angle), np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'y':\n",
    "        return np.array([\n",
    "            [np.cos(angle), 0, np.sin(angle), 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [-np.sin(angle), 0, np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'z':\n",
    "        return np.array([\n",
    "            [np.cos(angle), -np.sin(angle), 0, 0],\n",
    "            [np.sin(angle), np.cos(angle), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "def reflection_matrix():\n",
    "    \"\"\"\n",
    "    Create a reflection matrix to flip the Y-axis.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "def transform_to_carla(sensor_type, transformation):\n",
    "    \"\"\"\n",
    "    Convert sensor transformation to CARLA format.\n",
    "    \"\"\"\n",
    "    if sensor_type == 'camera':\n",
    "        rotation1 = rotation_matrix('z', np.pi / 2)\n",
    "        rotation2 = rotation_matrix('y', -np.pi / 2)\n",
    "        # rotation2 = np.eye(4)\n",
    "        rotation = np.dot(rotation1, rotation2)\n",
    "    elif sensor_type == 'lidar':\n",
    "        rotation = rotation_matrix('z', np.pi / 2)\n",
    "    elif sensor_type == 'radar':\n",
    "        rotation = np.eye(4) #rotation_matrix('x', np.pi / 2)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown sensor type\")\n",
    "    \n",
    "    tf = np.dot(transformation, rotation)\n",
    "    #reflection = reflection_matrix()\n",
    "    #tf = np.dot(reflection, tf)\n",
    "    return tf\n",
    "\n",
    "\n",
    "class URDFParser:\n",
    "    def __init__(self, urdf_file):\n",
    "        self.urdf_file = urdf_file\n",
    "        self.robot = urdf.URDF.from_xml_file(urdf_file)\n",
    "        self.root = self.robot.get_root()\n",
    "\n",
    "    def compute_chain_transform(self, chain):\n",
    "        transform = np.eye(4)\n",
    "        \n",
    "        for joint in chain:\n",
    "            if joint not in self.robot.joint_map:\n",
    "                continue\n",
    "            \n",
    "            joint_info = self.robot.joint_map[joint]\n",
    "            rpy = joint_info.origin.rpy\n",
    "            xyz = joint_info.origin.xyz\n",
    "            rotation = Rotation.from_euler('xyz', rpy).as_matrix()\n",
    "            translation = np.array(xyz)\n",
    "            T = build_transform_matrix(rotation, translation)\n",
    "            transform = np.dot(transform, T)\n",
    "        \n",
    "        return transform\n",
    "\n",
    "    def get_T_from_to(self, start_frame, end_frame):\n",
    "        chain_1 = self.robot.get_chain(self.root, start_frame)\n",
    "        chain_2 = self.robot.get_chain(self.root, end_frame)\n",
    "        T1 = self.compute_chain_transform(chain_1)\n",
    "        T2 = self.compute_chain_transform(chain_2)\n",
    "        return np.dot(np.linalg.inv(T1), T2)\n",
    "\n",
    "    def visualize(self, start_frame, end_frame):\n",
    "        fig = plt.figure(figsize=[6, 6])\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        for link in self.robot.links:\n",
    "            name = link.name\n",
    "            base_T_link = self.compute_chain_transform(self.robot.get_chain(self.root, name))\n",
    "            \n",
    "            linewidth = 1\n",
    "            if name == start_frame or name == end_frame:\n",
    "                linewidth = 5\n",
    "                ax.text(*base_T_link[:3, 3], name, fontsize=12)\n",
    "                \n",
    "            ax.quiver(*base_T_link[:3, 3], *base_T_link[:3, 0], color='r', linewidth=linewidth, length=0.2)  # X axis\n",
    "            ax.quiver(*base_T_link[:3, 3], *base_T_link[:3, 1], color='g', linewidth=linewidth, length=0.2)  # Y axis\n",
    "            ax.quiver(*base_T_link[:3, 3], *base_T_link[:3, 2], color='b', linewidth=linewidth, length=0.2)  # Z axis\n",
    "\n",
    "        ax.set_box_aspect([1, 1, 1])\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        \n",
    "    def visualize_o3d(self, start_frame, end_frame):\n",
    "        # Create a visualizer\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window()\n",
    "\n",
    "        for link in self.robot.links:\n",
    "            name = link.name\n",
    "            base_T_link = self.compute_chain_transform(self.robot.get_chain(self.root, name))\n",
    "\n",
    "            scale = 0.2\n",
    "            if name == start_frame or name == end_frame:\n",
    "                scale = 0.3\n",
    "\n",
    "            if 'LIDAR' in name:\n",
    "                base_T_link = transform_to_carla('lidar', base_T_link)\n",
    "            elif 'CAM' in name:\n",
    "                base_T_link = transform_to_carla('camera', base_T_link)\n",
    "            elif 'RADAR' in name:\n",
    "                base_T_link = transform_to_carla('radar', base_T_link)\n",
    "\n",
    "                \n",
    "            # Create a coordinate frame at the link position\n",
    "            frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=scale)\n",
    "            frame.transform(base_T_link)\n",
    "\n",
    "            # If the link is the start or end frame, scale the frame for emphasis\n",
    "             \n",
    "\n",
    "            # Add the frame to the visualizer\n",
    "            vis.add_geometry(frame)\n",
    "\n",
    "        # Run the visualizer\n",
    "        vis.run()\n",
    "\n",
    "        # Destroy the visualizer when done\n",
    "        vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrinsics = URDFParser('config/nuscenes.extrinsics.urdf')\n",
    "for link in extrinsics.robot.links:\n",
    "    name = link.name\n",
    "    base_T_link = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, name))\n",
    "    if 'LIDAR' in name:\n",
    "        base_T_link = transform_to_carla('lidar', base_T_link)\n",
    "    elif 'CAM' in name:\n",
    "        base_T_link = transform_to_carla('camera', base_T_link)\n",
    "    elif 'RADAR' in name:\n",
    "        base_T_link = transform_to_carla('radar', base_T_link)\n",
    "\n",
    "    xyz = base_T_link[:3, 3]\n",
    "    rpy = Rotation.from_matrix(base_T_link[:3, :3]).as_euler('xyz')\n",
    "    print(f\"{name}: xyz={xyz}, rpy={rpy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add pedestrians to simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pedestrians_to_simulation(n_pedestrians: int=0,\n",
    "                                  min_speed: float=1.0,\n",
    "                                  max_speed: float=2.0) -> None:\n",
    "    \"\"\"\n",
    "    Choose n_pedestrians amount of random pedestrians from Carla's\n",
    "    Blueprint Library, attach them to AI and spawn them to random \n",
    "    positions in the simulation. Set a random location for them to \n",
    "    walk to and speed between min_speed and max_speed for them to\n",
    "    walk at.\n",
    "\n",
    "    NB! If the randomly chosen spawn points collide, a pedestrian\n",
    "    is not spawned, so there might be fewer pedestrians than \n",
    "    n_pedestrians in the simulation.\n",
    "\n",
    "    Inputs:\n",
    "        n_pedestrians - number of pedestrians to spawn\n",
    "        min_speed - minimum walking speed for a pedestrian\n",
    "        max_speed - maximum walking speed for a pedestrian\n",
    "    \"\"\"\n",
    "    if n_pedestrians == 0:\n",
    "        return\n",
    "    \n",
    "    pedestrian_blueprints = blueprint_library.filter(\"walker.pedestrian.*\")\n",
    "    spawn_points = []\n",
    "    for i in range(n_pedestrians):\n",
    "        spawn_point = carla.Transform()\n",
    "        spawn_point.location = world.get_random_location_from_navigation()\n",
    "        if (spawn_point.location != None):\n",
    "            spawn_points.append(spawn_point)\n",
    "    batch = []\n",
    "\n",
    "    # Create a batch of spawn commands\n",
    "    for spawn_point in spawn_points:\n",
    "        pedestrian_bp = random.choice(pedestrian_blueprints)\n",
    "        batch.append(carla.command.SpawnActor(pedestrian_bp, spawn_point))\n",
    "\n",
    "    # Apply the batch of commands\n",
    "    results = client.apply_batch_sync(batch, True)\n",
    "    walkers_list = []\n",
    "    collisions = 0\n",
    "    for i in range(len(results)):\n",
    "        if results[i].error:\n",
    "            collisions += 1\n",
    "        else:\n",
    "            walkers_list.append({\"id\": results[i].actor_id})\n",
    "\n",
    "    if collisions:\n",
    "        print(f\"Failed to spawn {collisions}/{n_pedestrians} because of collisions\")\n",
    "\n",
    "    # Create a batch of spawn commands for AI controllers\n",
    "    batch = []\n",
    "    walker_controller_bp = blueprint_library.find('controller.ai.walker')\n",
    "    for i in range(len(walkers_list)):\n",
    "        batch.append(carla.command.SpawnActor(walker_controller_bp, carla.Transform(), walkers_list[i][\"id\"]))\n",
    "\n",
    "    # Apply the batch of commands\n",
    "    results = client.apply_batch_sync(batch, True)\n",
    "    for i in range(len(results)):\n",
    "        if results[i].error:\n",
    "            print(f\"Spawning pedestrian AI failed: {results[i].error}\")\n",
    "        else:\n",
    "            walkers_list[i][\"con\"] = results[i].actor_id\n",
    "\n",
    "    all_ids = []\n",
    "    for i in range(len(walkers_list)):\n",
    "        all_ids.append(walkers_list[i][\"con\"])\n",
    "        all_ids.append(walkers_list[i][\"id\"])\n",
    "    all_actors = world.get_actors(all_ids)\n",
    "\n",
    "    for i in range(0, len(all_actors), 2):\n",
    "        all_actors[i].start()\n",
    "        all_actors[i].go_to_location(world.get_random_location_from_navigation())\n",
    "        all_actors[i].set_max_speed(random.uniform(min_speed, max_speed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add vehicles to simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vehicles_to_simulation(n_vehicles: int=0):\n",
    "    \"\"\"\n",
    "    Choos n_vehicles amount of vehicles from Carla's Blueprint Library and\n",
    "    spawn them at random points on the map. Each of those vehicles are set\n",
    "    on autopilot and controlled by Carla's Traffic Manager.\n",
    "    \n",
    "    NB! If randomly chosen spawn points collide, the vehicle is not spawned\n",
    "    so there might be fewer vehicles than set by n_vehicles.\n",
    "\n",
    "    Inputs:\n",
    "        n_vehicles - amount of vehicles to spawn\n",
    "    \"\"\"\n",
    "    if n_vehicles == 0:\n",
    "        return\n",
    "    \n",
    "    spawn_points = map.get_spawn_points()\n",
    "    vehicle_blueprints = blueprint_library.filter('vehicle')\n",
    "    \n",
    "    npcs = []\n",
    "    collisions = 0\n",
    "    for _ in range(n_vehicles):\n",
    "        vehicle_bp = random.choice(vehicle_blueprints)\n",
    "        spawn_point = random.choice(spawn_points)\n",
    "        npc = world.try_spawn_actor(vehicle_bp, spawn_point)\n",
    "        if npc:\n",
    "            npcs.append(npc)\n",
    "        else:\n",
    "            collisions += 1\n",
    "    \n",
    "    if collisions:\n",
    "        print(f\"Failed to spawn {collisions}/{n_vehicles} vehicles because of collisions\")\n",
    "    \n",
    "    port = traffic_manager.get_port()\n",
    "    for npc in npcs:\n",
    "        npc.set_autopilot(True, port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_world()\n",
    "\n",
    "vehicles = []\n",
    "blueprint_name = \"vehicle.mini.cooper_s_2021\"\n",
    "blueprint = blueprint_library.find(blueprint_name)\n",
    "blueprint.set_attribute('role_name','ego')\n",
    "transform = spawn_points[20]\n",
    "vehicle = world.spawn_actor(blueprint, transform)\n",
    "port = traffic_manager.get_port()\n",
    "vehicle.set_autopilot(True, port)\n",
    "vehicles.append(vehicle)\n",
    "\n",
    "sensor_names = []\n",
    "sensor_types = []\n",
    "sensors = []\n",
    "\n",
    "axes = []\n",
    "\n",
    "extrinsics = URDFParser('config/nuscenes_car.urdf')\n",
    "intrinsics = dict()\n",
    "with open('config/nuscenes.intrinsics.json') as intrinsics_file:\n",
    "    intrinsics = json.load(intrinsics_file)\n",
    "\n",
    "for sensor_configuration in extrinsics.robot.links:\n",
    "    sensor_name = sensor_configuration.name\n",
    "\n",
    "    if \"_DEPTH_CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.depth\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = get_value(intrinsics, [sensor_name], default=dict())\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        field_of_view = str(sensor_intrinsics.get(\"fov\", 120))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('camera', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "    elif \"_SEMANTIC_CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.semantic_segmentation\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = get_value(intrinsics, [sensor_name], default=dict())\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        field_of_view = str(sensor_intrinsics.get(\"fov\", 120))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('camera', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "    elif \"CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.rgb\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = get_value(intrinsics, [sensor_name], default=dict())\n",
    "        focal_distance = str(sensor_intrinsics.get(\"fl\", 1260.0))\n",
    "        blueprint.set_attribute(\"focal_distance\", focal_distance)\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('camera', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "    elif \"RADAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.other.radar\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)     \n",
    "        blueprint.set_attribute('horizontal_fov', str(30.0)) \n",
    "        blueprint.set_attribute('vertical_fov', str(30.0)) \n",
    "        blueprint.set_attribute('points_per_second', str(1e5))\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('radar', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "\n",
    "\n",
    "    elif \"LIDAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.lidar.ray_cast_semantic\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute(\"channels\", str(64))\n",
    "        blueprint.set_attribute(\"points_per_second\", str(112000))\n",
    "        blueprint.set_attribute(\"range\", str(100))\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('lidar', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0, 0, 0])\n",
    "    frame.transform(transform_matrix)\n",
    "    axes.append(frame)\n",
    "        \n",
    "    sensors.append(sensor)\n",
    "    sensor_type = blueprint_name\n",
    "    sensor_types.append(sensor_type)\n",
    "    sensor_names.append(sensor_name)\n",
    "\n",
    "#o3d.visualization.draw_geometries(axes)\n",
    "add_pedestrians_to_simulation()\n",
    "add_vehicles_to_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of sensors spawned: {len(sensors)}\")\n",
    "print(sensor_names)\n",
    "print(sensor_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filesystem methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_in_directory(target_directory):\n",
    "    if os.path.exists(target_directory):\n",
    "        for filename in os.listdir(target_directory):\n",
    "            file_path = os.path.join(target_directory, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.remove(file_path) \n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "\n",
    "def create_filename_from_timestamp(timestamp):\n",
    "    SECONDS_TO_NANOSECONDS = 1000000000\n",
    "    filename = str(math.trunc(timestamp * SECONDS_TO_NANOSECONDS))\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General sensor processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sensor_position(raw_data, target_directory):\n",
    "    transform = raw_data.transform\n",
    "    transform_matrix = raw_data.transform.get_matrix()\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".npy\"\n",
    "    np.save(f\"{target_directory}/{filename}\", transform_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RBG Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rgb_image(raw_data, target_directory):    \n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    rgb_image = np.reshape(np.copy(raw_data.raw_data), (raw_data.height, raw_data.width, 4))\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    cv2.imwrite(f\"{directory}/{filename}\", rgb_image)\n",
    "\n",
    "def visualize_rgb_image(raw_image, window_name, window_size=None):\n",
    "    image = np.reshape(np.copy(raw_image.raw_data), (raw_image.height, raw_image.width, 4))\n",
    "    if window_size:\n",
    "         image = cv2.resize(image, dsize=window_size, interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(window_name, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Depth Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_depth_image(raw_image, window_name, window_size=None):\n",
    "    image = np.reshape(np.copy(raw_image.raw_data), (raw_image.height, raw_image.width, 4))\n",
    "    if window_size:\n",
    "         image = cv2.resize(image, dsize=window_size, interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(window_name, image)\n",
    "\n",
    "def save_depth_image(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")\n",
    "\n",
    "def convert_depth_image_to_depth_map(image):\n",
    "    depth_map = image[:, :, 0] + image[:, :, 1] * 256 + image[:, :, 2] * 256**2\n",
    "    depth_map = depth_map / (256**3 - 1) * 1000  # Convert to meters\n",
    "    return depth_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semantic Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticColors(Enum):\n",
    "    UNLABELED =     (0, 0, 0)\n",
    "    BUILDING =      (1, 0, 0)\n",
    "    FENCE =         (2, 0, 0)\n",
    "    OTHER =         (3, 0, 0)\n",
    "    PEDESTRIAN =    (4, 0, 0)\n",
    "    POLE =          (5, 0, 0)\n",
    "    ROADLINE =      (6, 0, 0)\n",
    "    ROAD =          (7, 0, 0)\n",
    "    SIDEWALK =      (8, 0, 0)\n",
    "    VEGETATION =    (9, 0, 0)\n",
    "    VEHICLES =      (10, 0, 0)\n",
    "    WALL =          (11, 0, 0)\n",
    "    TRAFFICSIGN =   (12, 0, 0)\n",
    "    SKY =           (13, 0, 0)\n",
    "    GROUND =        (14, 0, 0)\n",
    "    BRIDGE =        (15, 0, 0)\n",
    "    RAILTRACK =     (16, 0, 0)\n",
    "    GUARDRAIL =     (17, 0, 0)\n",
    "    TRAFFICLIGHT =  (18, 0, 0)\n",
    "    STATIC =        (19, 0, 0)\n",
    "    DYNAMIC =       (20, 0, 0)\n",
    "    WATER =         (21, 0, 0)\n",
    "    TERRAIN =       (22, 0, 0)\n",
    "\n",
    "def create_color_mask(image, colors):\n",
    "    mask = np.full((image.shape[0], image.shape[1]), 255, dtype=np.uint8)\n",
    "    \n",
    "    B, G, R = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    # Iterate through the list of colors\n",
    "    for color in colors:\n",
    "        # Extract color channels\n",
    "        r, g, b = color\n",
    "        # Create boolean masks for each channel comparison\n",
    "        r_mask = R == r\n",
    "        g_mask = G == g\n",
    "        b_mask = B == b\n",
    "        # Combine channel masks to get the final color mask\n",
    "        color_mask = r_mask & g_mask & b_mask\n",
    "        # Update the overall mask where any color matches\n",
    "        mask[color_mask] = 0\n",
    "    return mask\n",
    "\n",
    "def visualize_semantic_image(raw_image, window_name, window_size=None):\n",
    "    image = np.reshape(np.copy(raw_image.raw_data), (raw_image.height, raw_image.width, 4))\n",
    "    if window_size:\n",
    "         image = cv2.resize(image, dsize=window_size, interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(window_name, image)\n",
    "\n",
    "def save_semantic_image(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")\n",
    "\n",
    "def save_semantic_image_mask(raw_data, target_directory, masked_colors=[]):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    semantic_image = np.reshape(np.copy(raw_data.raw_data), (raw_data.height, raw_data.width, 4))\n",
    "    mask = create_color_mask(semantic_image, masked_colors)\n",
    "\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".mask.png\"\n",
    "    cv2.imwrite(f\"{directory}/{filename}\", mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Radar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_radar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    points = []\n",
    "\n",
    "    # Convert radar readings to 3D points (spherical to Cartesian)\n",
    "    radar_measurement = raw_data\n",
    "    \n",
    "    current_rot = raw_data.transform.rotation\n",
    "    current_trans = raw_data.transform.location\n",
    "\n",
    "    radar_points_list = []\n",
    "    for detect in radar_measurement:\n",
    "        azi = math.degrees(detect.azimuth)\n",
    "        alt = math.degrees(detect.altitude)\n",
    "        # The 0.25 adjusts a bit the distance so the dots can\n",
    "        # be properly seen\n",
    "        fw_vec = carla.Vector3D(x=detect.depth)\n",
    "        \n",
    "        carla.Transform(\n",
    "                carla.Location(),\n",
    "                carla.Rotation(\n",
    "                    pitch=alt,\n",
    "                    yaw=azi,\n",
    "                    roll=0)).transform(fw_vec)\n",
    "        \n",
    "        \n",
    "        radar_points_list.append([fw_vec.x, fw_vec.y, fw_vec.z])\n",
    "        \n",
    "        # norm_velocity = detect.velocity / self.velocity_range # range [-1, 1]\n",
    "        # r = int(clamp(0.0, 1.0, 1.0 - norm_velocity) * 255.0)\n",
    "        # g = int(clamp(0.0, 1.0, 1.0 - abs(norm_velocity)) * 255.0)\n",
    "        # b = int(abs(clamp(- 1.0, 0.0, - 1.0 - norm_velocity)) * 255.0)\n",
    "    \n",
    "    points = np.array(radar_points_list)\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    o3d.io.write_point_cloud(f\"{directory}/{filename}\", point_cloud)\n",
    "    \n",
    "    # for detection in radar_measurement:\n",
    "    #     # Extract the azimuth, altitude, depth from the radar detection\n",
    "    #     azimuth = detection.azimuth\n",
    "    #     altitude = detection.altitude\n",
    "    #     depth = detection.depth\n",
    "\n",
    "    #     # Convert spherical coordinates to Cartesian coordinates\n",
    "    #     x = depth * np.cos(altitude) * np.cos(azimuth)\n",
    "    #     y = depth * np.cos(altitude) * np.sin(azimuth)\n",
    "    #     z = depth * np.sin(altitude)\n",
    "        \n",
    "    #     points.append([x, y, z])\n",
    "\n",
    "    # # Create an Open3D point cloud object\n",
    "    # point_cloud = o3d.geometry.PointCloud()\n",
    "    # point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # # Save the point cloud to a .ply file\n",
    "    # filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    # o3d.io.write_point_cloud(f\"{directory}/{filename}\", point_cloud)\n",
    "\n",
    "\n",
    "def visualize_radar(raw_data, window_name, max_distance = 100, image_size=(200, 200)):\n",
    "    # Get the radar data\n",
    "    radar_data = raw_data.raw_data\n",
    "    points = np.frombuffer(radar_data, dtype=np.dtype('f4'))\n",
    "    points = np.reshape(points, (len(raw_data), 4))\n",
    "\n",
    "    # Extract information from radar points\n",
    "    azimuths = points[:, 1]\n",
    "    depths = points[:, 3]\n",
    "    X = np.cos(azimuths) * depths\n",
    "    Y = np.sin(azimuths) * depths\n",
    "\n",
    "    def normalize(data):\n",
    "        shifted = data - np.min(data)\n",
    "        normal = shifted / np.max(shifted)\n",
    "        return normal\n",
    "    width, height = 360, 360\n",
    "    X_norm = (normalize(X) * (width-1)).astype(int)\n",
    "    Y_norm = (normalize(Y) * (height-1)).astype(int)\n",
    "\n",
    "    radar_image_array = np.zeros((height, width))\n",
    "    radar_image_array[Y_norm, X_norm] = 255  # Set a constant value for visibility\n",
    "    cv2.imshow(window_name, radar_image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lidar methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lidar(raw_data, window_name):\n",
    "    # Get the LiDAR point cloud from the data\n",
    "    lidar_data = raw_data.raw_data\n",
    "    lidar_data = np.frombuffer(lidar_data, dtype=np.dtype('f4'))\n",
    "    lidar_data = np.reshape(lidar_data, (int(lidar_data.shape[0] / 4), 4))\n",
    "\n",
    "    # Extract X, Y, Z coordinates and intensity values\n",
    "    points_xyz = lidar_data[:, :3]\n",
    "    #intensity = lidar_data[:, 3]\n",
    "\n",
    "    # Intensity scaling factor\n",
    "    intensity_scale = 2.0  # Adjust this value to control the brightness\n",
    "\n",
    "    # Create a 2D histogram with a predetermined size\n",
    "    width, height = 360, 360\n",
    "    lidar_image_array = np.zeros((height, width))\n",
    "\n",
    "    # Scale and shift X and Y coordinates to fit within the histogram size\n",
    "    def normalize(data):\n",
    "        shifted = data - np.min(data)\n",
    "        normal = shifted / np.max(shifted)\n",
    "        return normal\n",
    "    X = (normalize(points_xyz[:, 0]) * (width-1)).astype(int)\n",
    "    Y = (normalize(points_xyz[:, 1]) * (height-1)).astype(int)\n",
    "\n",
    "    # Assign scaled intensity values to the corresponding pixel in the histogram\n",
    "    lidar_image_array[Y, X] = 255\n",
    "\n",
    "    # Display the processed image using Pygame\n",
    "    cv2.imshow(window_name, lidar_image_array)\n",
    "\n",
    "def save_lidar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semantic Lidar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticTags(Enum):\n",
    "    UNLABELED =     0\n",
    "    BUILDING =      1\n",
    "    FENCE =         2\n",
    "    OTHER =         3\n",
    "    PEDESTRIAN =    4\n",
    "    POLE =          5\n",
    "    ROADLINE =      6\n",
    "    ROAD =          7\n",
    "    SIDEWALK =      8\n",
    "    VEGETATION =    9\n",
    "    VEHICLES =      10\n",
    "    WALL =          11\n",
    "    TRAFFICSIGN =   12\n",
    "    SKY =           13\n",
    "    GROUND =        14\n",
    "    BRIDGE =        15\n",
    "    RAILTRACK =     16\n",
    "    GUARDRAIL =     17\n",
    "    TRAFFICLIGHT =  18\n",
    "    STATIC =        19\n",
    "    DYNAMIC =       20\n",
    "    WATER =         21\n",
    "    TERRAIN =       22\n",
    "\n",
    "\n",
    "def filter_semantic_lidar_readings(semantic_lidar_data):\n",
    "    #print(np.unique(semantic_tags, return_counts=True))\n",
    "    filtered_lidar_data = np.copy(semantic_lidar_data)\n",
    "    \n",
    "    unwanted_data_tags = np.array([\n",
    "        SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, SemanticTags.SIDEWALK.value,\n",
    "        SemanticTags.GROUND.value, SemanticTags.WATER.value, SemanticTags.TERRAIN.value\n",
    "    ]) \n",
    "    if len(unwanted_data_tags) > 0:\n",
    "        data_tags = filtered_lidar_data[:, 3].flatten()\n",
    "        filter_mask = np.isin(data_tags, unwanted_data_tags, invert=True)\n",
    "        filtered_lidar_data = filtered_lidar_data[filter_mask]\n",
    "    \n",
    "    z_range = None\n",
    "    if z_range:\n",
    "        z_min, z_max = z_range\n",
    "        z_values = filtered_lidar_data[:, 2:3].flatten()\n",
    "        filter_mask = np.where(z_min <= z_values, True, False) * np.where(z_values <= z_max, True, False)\n",
    "        filtered_lidar_data = filtered_lidar_data[filter_mask]\n",
    "    \n",
    "    return filtered_lidar_data\n",
    "\n",
    "def visualize_semantic_lidar(raw_data, window_name):\n",
    "    # Get the LiDAR point cloud from the data\n",
    "    lidar_data = np.array([(detection.point.x, detection.point.y, detection.point.z, int(detection.object_tag)) for detection in raw_data])\n",
    "    lidar_data = filter_semantic_lidar_readings(lidar_data)\n",
    "\n",
    "    # Extract X, Y, Z coordinates and intensity values\n",
    "    points_xyz = lidar_data[:, :3]\n",
    "\n",
    "    # Create a 2D histogram with a predetermined size\n",
    "    width, height = 360, 360\n",
    "    lidar_image_array = np.zeros((height, width))\n",
    "\n",
    "    # Scale and shift X and Y coordinates to fit within the histogram size\n",
    "    def normalize(data):\n",
    "        shifted = data - np.min(data)\n",
    "        normal = shifted / np.max(shifted)\n",
    "        return normal\n",
    "    X = (normalize(points_xyz[:, 0]) * (width-1)).astype(int)\n",
    "    Y = (normalize(points_xyz[:, 1]) * (height-1)).astype(int)\n",
    "\n",
    "    # Assign scaled intensity values to the corresponding pixel in the histogram\n",
    "    lidar_image_array[Y, X] = 255\n",
    "\n",
    "    # Display the processed image using Pygame\n",
    "    cv2.imshow(window_name, lidar_image_array)\n",
    "\n",
    "def save_semantic_lidar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    lidar_data = np.array([(detection.point.x, detection.point.y, detection.point.z, int(detection.object_tag)) for detection in raw_data])\n",
    "    lidar_data = filter_semantic_lidar_readings(lidar_data)\n",
    "    points = lidar_data[:, :3]\n",
    "    # Create an Open3D point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # Save the point cloud to a .ply file\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    o3d.io.write_point_cloud(f\"{target_directory}/{filename}\", point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATED_DATA_DIRECTORY = \"./generated_data\"\n",
    "delete_all_in_directory(SIMULATED_DATA_DIRECTORY)\n",
    "\n",
    "cv2.namedWindow(\"Press Q to stop simulation\")\n",
    "cv2.imshow(\"Press Q to stop simulation\", np.zeros((1,1)))\n",
    "\n",
    "try:\n",
    "    with CarlaSyncMode(world, sensors, fps=10) as sync_mode:\n",
    "        while True:\n",
    "            simulation_results = sync_mode.tick(timeout=300.0)[1:]\n",
    "            for i in range(len(simulation_results)):\n",
    "                sensor = sensors[i]\n",
    "                sensor_data = simulation_results[i]\n",
    "                sensor_name = sensor_names[i].replace(\"base_link_to_\", \"\")\n",
    "                sensor_type = sensor_types[i]\n",
    "                if (\"camera.rgb\" in sensor_type):\n",
    "                    #visualize_rgb_image(sensor_data, sensor_name, window_size = (480, 270))\n",
    "                    save_rgb_image(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"camera.semantic_segmentation\" in sensor_type):\n",
    "                    #visualize_semantic_image(sensor_data, sensor_name, window_size = (480, 270))\n",
    "                    save_semantic_image(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                    save_semantic_image_mask(sensor_data, f\"generated_data/{sensor_name}/\", masked_colors=[\n",
    "                        SemanticColors.ROADLINE.value, SemanticColors.ROAD.value, SemanticColors.SIDEWALK.value,\n",
    "                        SemanticColors.GROUND.value, SemanticColors.WATER.value, SemanticColors.TERRAIN.value,\n",
    "                        SemanticColors.SKY.value\n",
    "                    ])\n",
    "                elif (\"sensor.other.radar\" in sensor_type):\n",
    "                    #visualize_radar(sensor_data, sensor_name)\n",
    "                    save_radar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"camera.depth\" in sensor_type):\n",
    "                    #visualize_depth_image(sensor_data, sensor_name, window_size = (480, 270))\n",
    "                    save_depth_image(sensor_data, f\"generated_data/{sensor_name}/\") \n",
    "                elif (\"sensor.lidar.ray_cast_semantic\" in sensor_type):\n",
    "                    #visualize_semantic_lidar(sensor_data, sensor_name)\n",
    "                    save_semantic_lidar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"sensor.lidar\" in sensor_type):\n",
    "                    #visualize_lidar(sensor_data, sensor_name)\n",
    "                    save_lidar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                save_sensor_position(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "            # for vehicle in vehicles:\n",
    "            #     position = map.get_waypoint(vehicle.get_transform().location)\n",
    "            #     # next_postition = random.choice(position.next(1.5))\n",
    "            #     next_postition = random.choice(position.next(5.0))\n",
    "            #     vehicle.set_transform(next_postition.transform)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    for sensor in sensors:\n",
    "        sensor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

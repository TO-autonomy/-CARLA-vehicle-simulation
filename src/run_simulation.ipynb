{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import carla\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import queue\n",
    "from matplotlib import cm\n",
    "import shutil \n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import urdf_parser_py.urdf as urdf\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to CARLA server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10)\n",
    "world = client.get_world()\n",
    "map = world.get_map()\n",
    "\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_world():\n",
    "    global world, map, blueprint_library, spawn_points\n",
    "    world = client.reload_world()\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "def load_world(map_name=\"Town01\", timeout=10.0):\n",
    "    global world, map, blueprint_library, spawn_points\n",
    "    client.set_timeout(timeout)\n",
    "    world = client.load_world(map_name)\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 5)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds,\n",
    "            ))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout):\n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read simulation configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(data_dict, keys, default=None):\n",
    "    for key in keys:\n",
    "        if isinstance(data_dict, dict):\n",
    "            data_dict = data_dict.get(key, default)\n",
    "        else:\n",
    "            return default\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_transform(matrix):\n",
    "    # Extract translation\n",
    "    location = carla.Location(x=matrix[0, 3], y=(-matrix[1, 3]), z=matrix[2, 3])\n",
    "\n",
    "    roll, pitch, yaw = Rotation.from_matrix(matrix[:3, :3]).as_euler('xyz', degrees=True)\n",
    "    rotation = carla.Rotation(pitch=(-pitch), yaw=(-yaw), roll=roll)\n",
    "    \n",
    "    # Create and return carla.Transform\n",
    "    return carla.Transform(location, rotation)\n",
    "\n",
    "\n",
    "def build_transform_matrix(rotation, translation):\n",
    "    m = np.eye(4)\n",
    "    m[:3, :3] = rotation\n",
    "    m[:3, 3] = translation\n",
    "    return m\n",
    "\n",
    "\n",
    "def rotation_matrix(axis, angle):\n",
    "    \"\"\"\n",
    "    Create a rotation matrix for a given axis and angle.\n",
    "    \"\"\"\n",
    "    if axis == 'x':\n",
    "        return np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, np.cos(angle), -np.sin(angle), 0],\n",
    "            [0, np.sin(angle), np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'y':\n",
    "        return np.array([\n",
    "            [np.cos(angle), 0, np.sin(angle), 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [-np.sin(angle), 0, np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'z':\n",
    "        return np.array([\n",
    "            [np.cos(angle), -np.sin(angle), 0, 0],\n",
    "            [np.sin(angle), np.cos(angle), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "def reflection_matrix():\n",
    "    \"\"\"\n",
    "    Create a reflection matrix to flip the Y-axis.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "def transform_to_carla(sensor_type, transformation):\n",
    "    \"\"\"\n",
    "    Convert sensor transformation to CARLA format.\n",
    "    \"\"\"\n",
    "    if sensor_type == 'camera':\n",
    "        # Rotate around Y-axis by 90 degrees\n",
    "        rotation1 = rotation_matrix('z', np.pi / 2)\n",
    "        rotation2 = rotation_matrix('y', -np.pi / 2)\n",
    "        # rotation2 = np.eye(4)\n",
    "        rotation = np.dot(rotation1, rotation2)\n",
    "    elif sensor_type == 'lidar':\n",
    "        # Rotate around X-axis by -90 degrees\n",
    "        rotation = rotation_matrix('z', np.pi / 2)\n",
    "    elif sensor_type == 'radar':\n",
    "        # Rotate around Z-axis by -90 degrees\n",
    "        rotation = np.eye(4)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown sensor type\")\n",
    "    \n",
    "    tf = np.dot(transformation, rotation)\n",
    "    #reflection = reflection_matrix()\n",
    "    #tf = np.dot(reflection, tf)\n",
    "    return tf\n",
    "\n",
    "\n",
    "class URDFParser:\n",
    "    def __init__(self, urdf_file):\n",
    "        self.urdf_file = urdf_file\n",
    "        self.robot = urdf.URDF.from_xml_file(urdf_file)\n",
    "        self.root = self.robot.get_root()\n",
    "\n",
    "    def compute_chain_transform(self, chain):\n",
    "        transform = np.eye(4)\n",
    "        \n",
    "        for joint in chain:\n",
    "            if joint not in self.robot.joint_map:\n",
    "                continue\n",
    "            \n",
    "            joint_info = self.robot.joint_map[joint]\n",
    "            rpy = joint_info.origin.rpy\n",
    "            xyz = joint_info.origin.xyz\n",
    "            rotation = Rotation.from_euler('xyz', rpy).as_matrix()\n",
    "            translation = np.array(xyz)\n",
    "            T = build_transform_matrix(rotation, translation)\n",
    "            transform = np.dot(transform, T)\n",
    "        \n",
    "        return transform\n",
    "\n",
    "    def get_T_from_to(self, start_frame, end_frame):\n",
    "        chain_1 = self.robot.get_chain(self.root, start_frame)\n",
    "        chain_2 = self.robot.get_chain(self.root, end_frame)\n",
    "        T1 = self.compute_chain_transform(chain_1)\n",
    "        T2 = self.compute_chain_transform(chain_2)\n",
    "        return np.dot(np.linalg.inv(T1), T2)\n",
    "\n",
    "    def visualize(self, start_frame, end_frame):\n",
    "        fig = plt.figure(figsize=[6, 6])\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        for link in self.robot.links:\n",
    "            name = link.name\n",
    "            base_T_link = self.compute_chain_transform(self.robot.get_chain(self.root, name))\n",
    "            \n",
    "            linewidth = 1\n",
    "            if name == start_frame or name == end_frame:\n",
    "                linewidth = 5\n",
    "                ax.text(*base_T_link[:3, 3], name, fontsize=12)\n",
    "                \n",
    "            ax.quiver(*base_T_link[:3, 3], *base_T_link[:3, 0], color='r', linewidth=linewidth, length=0.2)  # X axis\n",
    "            ax.quiver(*base_T_link[:3, 3], *base_T_link[:3, 1], color='g', linewidth=linewidth, length=0.2)  # Y axis\n",
    "            ax.quiver(*base_T_link[:3, 3], *base_T_link[:3, 2], color='b', linewidth=linewidth, length=0.2)  # Z axis\n",
    "\n",
    "        ax.set_box_aspect([1, 1, 1])\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        \n",
    "    def visualize_o3d(self, start_frame, end_frame):\n",
    "        # Create a visualizer\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window()\n",
    "\n",
    "        for link in self.robot.links:\n",
    "            name = link.name\n",
    "            base_T_link = self.compute_chain_transform(self.robot.get_chain(self.root, name))\n",
    "\n",
    "            scale = 0.2\n",
    "            if name == start_frame or name == end_frame:\n",
    "                scale = 0.3\n",
    "\n",
    "            if 'LIDAR' in name:\n",
    "                base_T_link = transform_to_carla('lidar', base_T_link)\n",
    "            elif 'CAM' in name:\n",
    "                base_T_link = transform_to_carla('camera', base_T_link)\n",
    "            elif 'RADAR' in name:\n",
    "                base_T_link = transform_to_carla('radar', base_T_link)\n",
    "\n",
    "                \n",
    "            # Create a coordinate frame at the link position\n",
    "            frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=scale)\n",
    "            frame.transform(base_T_link)\n",
    "\n",
    "            # If the link is the start or end frame, scale the frame for emphasis\n",
    "             \n",
    "\n",
    "            # Add the frame to the visualizer\n",
    "            vis.add_geometry(frame)\n",
    "\n",
    "        # Run the visualizer\n",
    "        vis.run()\n",
    "\n",
    "        # Destroy the visualizer when done\n",
    "        vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAM_BACK_RIGHT: xyz=[ 1.0148781  -0.48056822  1.56239545], rpy=[ 0.01080667  0.01626668 -1.93363654]\n",
      "RADAR_FRONT_LEFT: xyz=[2.422 0.8   0.78 ], rpy=[0.         0.         1.54217293]\n",
      "RADAR_FRONT_RIGHT: xyz=[ 2.422 -0.8    0.77 ], rpy=[ 0.          0.         -1.58790055]\n",
      "base_link: xyz=[0. 0. 0.], rpy=[0. 0. 0.]\n",
      "RADAR_FRONT: xyz=[3.412 0.    0.5  ], rpy=[0.         0.         0.00349066]\n",
      "RADAR_BACK_LEFT: xyz=[-0.562  0.628  0.53 ], rpy=[0.         0.         3.04402875]\n",
      "LIDAR_TOP: xyz=[0.943713 0.       1.84023 ], rpy=[0.00590142 0.02423173 0.0021763 ]\n",
      "CAM_FRONT: xyz=[1.70079119 0.01594563 1.51095764], rpy=[-0.00080508  0.00564136  0.00568027]\n",
      "CAM_FRONT_RIGHT: xyz=[ 1.55084775 -0.4934048   1.49574801], rpy=[ 0.00905638  0.01364833 -0.98431885]\n",
      "CAM_BACK_LEFT: xyz=[1.035691   0.48479503 1.59097015], rpy=[-0.00375613  0.0160109   1.89537173]\n",
      "CAM_FRONT_LEFT: xyz=[1.52387798 0.49463134 1.50932822], rpy=[ 0.00211947 -0.00244738  0.96273526]\n",
      "CAM_BACK: xyz=[0.02832603 0.00345137 1.57910346], rpy=[ 0.0040008  -0.01674462  3.13910393]\n",
      "RADAR_BACK_RIGHT: xyz=[-0.562 -0.618  0.53 ], rpy=[ 0.          0.         -3.07369935]\n"
     ]
    }
   ],
   "source": [
    "extrinsics = URDFParser('config/nuscenes.extrinsics.urdf')\n",
    "for link in extrinsics.robot.links:\n",
    "    name = link.name\n",
    "    base_T_link = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, name))\n",
    "    if 'LIDAR' in name:\n",
    "        base_T_link = transform_to_carla('lidar', base_T_link)\n",
    "    elif 'CAM' in name:\n",
    "        base_T_link = transform_to_carla('camera', base_T_link)\n",
    "    elif 'RADAR' in name:\n",
    "        base_T_link = transform_to_carla('radar', base_T_link)\n",
    "\n",
    "    xyz = base_T_link[:3, 3]\n",
    "    rpy = Rotation.from_matrix(base_T_link[:3, :3]).as_euler('xyz')\n",
    "    print(f\"{name}: xyz={xyz}, rpy={rpy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_world()\n",
    "\n",
    "vehicles = []\n",
    "blueprint_name = \"vehicle.kawasaki.ninja\"\n",
    "blueprint = blueprint_library.find(blueprint_name)\n",
    "blueprint.set_attribute('role_name','ego')\n",
    "transform = spawn_points[20]\n",
    "vehicle = world.spawn_actor(blueprint, transform)\n",
    "vehicles.append(vehicle)\n",
    "\n",
    "sensor_names = []\n",
    "sensor_types = []\n",
    "sensors = []\n",
    "\n",
    "axes = []\n",
    "\n",
    "extrinsics = URDFParser('config/nuscenes.extrinsics.urdf')\n",
    "intrinsics = dict()\n",
    "with open('config/nuscenes.intrinsics.json') as intrinsics_file:\n",
    "    intrinsics = json.load(intrinsics_file)\n",
    "\n",
    "for sensor_configuration in extrinsics.robot.links:\n",
    "    sensor_name = sensor_configuration.name\n",
    "\n",
    "    if \"_DEPTH_CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.depth\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = get_value(intrinsics, [sensor_name], default=dict())\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        field_of_view = str(sensor_intrinsics.get(\"fov\", 120))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        \n",
    "        transform_matrix = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, sensor_name))\n",
    "        transform_matrix = transform_to_carla('camera', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "    elif \"_SEMANTIC_CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.semantic_segmentation\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = get_value(intrinsics, [sensor_name], default=dict())\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        field_of_view = str(sensor_intrinsics.get(\"fov\", 120))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        \n",
    "        transform_matrix = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, sensor_name))\n",
    "        transform_matrix = transform_to_carla('camera', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "    elif \"CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.rgb\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = get_value(intrinsics, [sensor_name], default=dict())\n",
    "        focal_distance = str(sensor_intrinsics.get(\"fl\", 1260.0))\n",
    "        blueprint.set_attribute(\"focal_distance\", focal_distance)\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        \n",
    "        transform_matrix = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, sensor_name))\n",
    "        transform_matrix = transform_to_carla('camera', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "    elif \"RADAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.other.radar\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)     \n",
    "        blueprint.set_attribute('horizontal_fov', str(360.0)) \n",
    "        \n",
    "        transform_matrix = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, sensor_name))\n",
    "        transform_matrix = transform_to_carla('radar', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "\n",
    "\n",
    "    elif \"LIDAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.lidar.ray_cast_semantic\"\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute(\"channels\", str(64))\n",
    "        blueprint.set_attribute(\"points_per_second\", str(112000))\n",
    "        blueprint.set_attribute(\"range\", str(100))\n",
    "        \n",
    "        transform_matrix = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, sensor_name))\n",
    "        transform_matrix = transform_to_carla('lidar', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0, 0, 0])\n",
    "    frame.transform(transform_matrix)\n",
    "    axes.append(frame)\n",
    "        \n",
    "    sensors.append(sensor)\n",
    "    sensor_type = blueprint_name\n",
    "    sensor_types.append(sensor_type)\n",
    "    sensor_names.append(sensor_name)\n",
    "\n",
    "o3d.visualization.draw_geometries(axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sensors spawned: 12\n",
      "['CAM_BACK_RIGHT', 'RADAR_FRONT_LEFT', 'RADAR_FRONT_RIGHT', 'RADAR_FRONT', 'RADAR_BACK_LEFT', 'LIDAR_TOP', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'RADAR_BACK_RIGHT']\n",
      "['sensor.camera.rgb', 'sensor.other.radar', 'sensor.other.radar', 'sensor.other.radar', 'sensor.other.radar', 'sensor.lidar.ray_cast_semantic', 'sensor.camera.rgb', 'sensor.camera.rgb', 'sensor.camera.rgb', 'sensor.camera.rgb', 'sensor.camera.rgb', 'sensor.other.radar']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of sensors spawned: {len(sensors)}\")\n",
    "print(sensor_names)\n",
    "print(sensor_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filesystem methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_in_directory(target_directory):\n",
    "    if os.path.exists(target_directory):\n",
    "        for filename in os.listdir(target_directory):\n",
    "            file_path = os.path.join(target_directory, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.remove(file_path) \n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "\n",
    "def create_filename_from_timestamp(timestamp):\n",
    "    SECONDS_TO_NANOSECONDS = 1000000000\n",
    "    filename = str(math.trunc(timestamp * SECONDS_TO_NANOSECONDS))\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General sensor processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sensor_position(raw_data, target_directory):\n",
    "    transform = raw_data.transform\n",
    "    transform_matrix = raw_data.transform.get_matrix()\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".npy\"\n",
    "    np.save(f\"{target_directory}/{filename}\", transform_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RBG Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rgb_image(raw_data, target_directory):    \n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    rgb_image = np.reshape(np.copy(raw_data.raw_data), (raw_data.height, raw_data.width, 4))\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    cv2.imwrite(f\"{directory}/{filename}\", rgb_image)\n",
    "\n",
    "def visualize_rgb_image(raw_image, window_name, window_size=None):\n",
    "    image = np.reshape(np.copy(raw_image.raw_data), (raw_image.height, raw_image.width, 4))\n",
    "    if window_size:\n",
    "         image = cv2.resize(image, dsize=window_size, interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(window_name, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Depth Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_depth_image(raw_image, window_name, window_size=None):\n",
    "    image = np.reshape(np.copy(raw_image.raw_data), (raw_image.height, raw_image.width, 4))\n",
    "    if window_size:\n",
    "         image = cv2.resize(image, dsize=window_size, interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(window_name, image)\n",
    "\n",
    "def save_depth_image(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")\n",
    "\n",
    "def convert_depth_image_to_depth_map(image):\n",
    "    depth_map = image[:, :, 0] + image[:, :, 1] * 256 + image[:, :, 2] * 256**2\n",
    "    depth_map = depth_map / (256**3 - 1) * 1000  # Convert to meters\n",
    "    return depth_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semantic Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticColors(Enum):\n",
    "    UNLABELED =     (0, 0, 0)\n",
    "    BUILDING =      (1, 0, 0)\n",
    "    FENCE =         (2, 0, 0)\n",
    "    OTHER =         (3, 0, 0)\n",
    "    PEDESTRIAN =    (4, 0, 0)\n",
    "    POLE =          (5, 0, 0)\n",
    "    ROADLINE =      (6, 0, 0)\n",
    "    ROAD =          (7, 0, 0)\n",
    "    SIDEWALK =      (8, 0, 0)\n",
    "    VEGETATION =    (9, 0, 0)\n",
    "    VEHICLES =      (10, 0, 0)\n",
    "    WALL =          (11, 0, 0)\n",
    "    TRAFFICSIGN =   (12, 0, 0)\n",
    "    SKY =           (13, 0, 0)\n",
    "    GROUND =        (14, 0, 0)\n",
    "    BRIDGE =        (15, 0, 0)\n",
    "    RAILTRACK =     (16, 0, 0)\n",
    "    GUARDRAIL =     (17, 0, 0)\n",
    "    TRAFFICLIGHT =  (18, 0, 0)\n",
    "    STATIC =        (19, 0, 0)\n",
    "    DYNAMIC =       (20, 0, 0)\n",
    "    WATER =         (21, 0, 0)\n",
    "    TERRAIN =       (22, 0, 0)\n",
    "\n",
    "def create_color_mask(image, colors):\n",
    "    mask = np.full((image.shape[0], image.shape[1]), 255, dtype=np.uint8)\n",
    "    \n",
    "    B, G, R = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    # Iterate through the list of colors\n",
    "    for color in colors:\n",
    "        # Extract color channels\n",
    "        r, g, b = color\n",
    "        # Create boolean masks for each channel comparison\n",
    "        r_mask = R == r\n",
    "        g_mask = G == g\n",
    "        b_mask = B == b\n",
    "        # Combine channel masks to get the final color mask\n",
    "        color_mask = r_mask & g_mask & b_mask\n",
    "        # Update the overall mask where any color matches\n",
    "        mask[color_mask] = 0\n",
    "    return mask\n",
    "\n",
    "def visualize_semantic_image(raw_image, window_name, window_size=None):\n",
    "    image = np.reshape(np.copy(raw_image.raw_data), (raw_image.height, raw_image.width, 4))\n",
    "    if window_size:\n",
    "         image = cv2.resize(image, dsize=window_size, interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(window_name, image)\n",
    "\n",
    "def save_semantic_image(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")\n",
    "\n",
    "def save_semantic_image_mask(raw_data, target_directory, masked_colors=[]):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    semantic_image = np.reshape(np.copy(raw_data.raw_data), (raw_data.height, raw_data.width, 4))\n",
    "    mask = create_color_mask(semantic_image, masked_colors)\n",
    "\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".mask.png\"\n",
    "    cv2.imwrite(f\"{directory}/{filename}\", mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Radar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_radar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    points = []\n",
    "\n",
    "    # Convert radar readings to 3D points (spherical to Cartesian)\n",
    "    radar_measurement = raw_data\n",
    "    for detection in radar_measurement:\n",
    "        # Extract the azimuth, altitude, depth from the radar detection\n",
    "        azimuth = detection.azimuth\n",
    "        altitude = detection.altitude\n",
    "        depth = detection.depth\n",
    "\n",
    "        # Convert spherical coordinates to Cartesian coordinates\n",
    "        x = depth * np.cos(altitude) * np.sin(azimuth)\n",
    "        y = depth * np.sin(altitude)\n",
    "        z = depth * np.cos(altitude) * np.cos(azimuth)\n",
    "\n",
    "        points.append([x, y, z])\n",
    "\n",
    "    # Create an Open3D point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # Save the point cloud to a .ply file\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    o3d.io.write_point_cloud(f\"{directory}/{filename}\", point_cloud)\n",
    "\n",
    "\n",
    "def visualize_radar(raw_data, window_name, max_distance = 100, image_size=(200, 200)):\n",
    "    # Get the radar data\n",
    "    radar_data = raw_data.raw_data\n",
    "    points = np.frombuffer(radar_data, dtype=np.dtype('f4'))\n",
    "    points = np.reshape(points, (len(raw_data), 4))\n",
    "\n",
    "    # Extract information from radar points\n",
    "    azimuths = points[:, 1]\n",
    "    depths = points[:, 3]\n",
    "    X = np.cos(azimuths) * depths\n",
    "    Y = np.sin(azimuths) * depths\n",
    "\n",
    "    def normalize(data):\n",
    "        shifted = data - np.min(data)\n",
    "        normal = shifted / np.max(shifted)\n",
    "        return normal\n",
    "    width, height = 360, 360\n",
    "    X_norm = (normalize(X) * (width-1)).astype(int)\n",
    "    Y_norm = (normalize(Y) * (height-1)).astype(int)\n",
    "\n",
    "    radar_image_array = np.zeros((height, width))\n",
    "    radar_image_array[Y_norm, X_norm] = 255  # Set a constant value for visibility\n",
    "    cv2.imshow(window_name, radar_image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lidar methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lidar(raw_data, window_name):\n",
    "    # Get the LiDAR point cloud from the data\n",
    "    lidar_data = raw_data.raw_data\n",
    "    lidar_data = np.frombuffer(lidar_data, dtype=np.dtype('f4'))\n",
    "    lidar_data = np.reshape(lidar_data, (int(lidar_data.shape[0] / 4), 4))\n",
    "\n",
    "    # Extract X, Y, Z coordinates and intensity values\n",
    "    points_xyz = lidar_data[:, :3]\n",
    "    #intensity = lidar_data[:, 3]\n",
    "\n",
    "    # Intensity scaling factor\n",
    "    intensity_scale = 2.0  # Adjust this value to control the brightness\n",
    "\n",
    "    # Create a 2D histogram with a predetermined size\n",
    "    width, height = 360, 360\n",
    "    lidar_image_array = np.zeros((height, width))\n",
    "\n",
    "    # Scale and shift X and Y coordinates to fit within the histogram size\n",
    "    def normalize(data):\n",
    "        shifted = data - np.min(data)\n",
    "        normal = shifted / np.max(shifted)\n",
    "        return normal\n",
    "    X = (normalize(points_xyz[:, 0]) * (width-1)).astype(int)\n",
    "    Y = (normalize(points_xyz[:, 1]) * (height-1)).astype(int)\n",
    "\n",
    "    # Assign scaled intensity values to the corresponding pixel in the histogram\n",
    "    lidar_image_array[Y, X] = 255\n",
    "\n",
    "    # Display the processed image using Pygame\n",
    "    cv2.imshow(window_name, lidar_image_array)\n",
    "\n",
    "def save_lidar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semantic Lidar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticTags(Enum):\n",
    "    UNLABELED =     0\n",
    "    BUILDING =      1\n",
    "    FENCE =         2\n",
    "    OTHER =         3\n",
    "    PEDESTRIAN =    4\n",
    "    POLE =          5\n",
    "    ROADLINE =      6\n",
    "    ROAD =          7\n",
    "    SIDEWALK =      8\n",
    "    VEGETATION =    9\n",
    "    VEHICLES =      10\n",
    "    WALL =          11\n",
    "    TRAFFICSIGN =   12\n",
    "    SKY =           13\n",
    "    GROUND =        14\n",
    "    BRIDGE =        15\n",
    "    RAILTRACK =     16\n",
    "    GUARDRAIL =     17\n",
    "    TRAFFICLIGHT =  18\n",
    "    STATIC =        19\n",
    "    DYNAMIC =       20\n",
    "    WATER =         21\n",
    "    TERRAIN =       22\n",
    "\n",
    "\n",
    "def filter_semantic_lidar_readings(semantic_lidar_data):\n",
    "    #print(np.unique(semantic_tags, return_counts=True))\n",
    "    filtered_lidar_data = np.copy(semantic_lidar_data)\n",
    "    \n",
    "    unwanted_data_tags = np.array([\n",
    "        SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, SemanticTags.SIDEWALK.value,\n",
    "        SemanticTags.GROUND.value, SemanticTags.WATER.value, SemanticTags.TERRAIN.value\n",
    "    ]) \n",
    "    if len(unwanted_data_tags) > 0:\n",
    "        data_tags = filtered_lidar_data[:, 3].flatten()\n",
    "        filter_mask = np.isin(data_tags, unwanted_data_tags, invert=True)\n",
    "        filtered_lidar_data = filtered_lidar_data[filter_mask]\n",
    "    \n",
    "    z_range = None\n",
    "    if z_range:\n",
    "        z_min, z_max = z_range\n",
    "        z_values = filtered_lidar_data[:, 2:3].flatten()\n",
    "        filter_mask = np.where(z_min <= z_values, True, False) * np.where(z_values <= z_max, True, False)\n",
    "        filtered_lidar_data = filtered_lidar_data[filter_mask]\n",
    "    \n",
    "    return filtered_lidar_data\n",
    "\n",
    "def visualize_semantic_lidar(raw_data, window_name):\n",
    "    # Get the LiDAR point cloud from the data\n",
    "    lidar_data = np.array([(detection.point.x, detection.point.y, detection.point.z, int(detection.object_tag)) for detection in raw_data])\n",
    "    lidar_data = filter_semantic_lidar_readings(lidar_data)\n",
    "\n",
    "    # Extract X, Y, Z coordinates and intensity values\n",
    "    points_xyz = lidar_data[:, :3]\n",
    "\n",
    "    # Create a 2D histogram with a predetermined size\n",
    "    width, height = 360, 360\n",
    "    lidar_image_array = np.zeros((height, width))\n",
    "\n",
    "    # Scale and shift X and Y coordinates to fit within the histogram size\n",
    "    def normalize(data):\n",
    "        shifted = data - np.min(data)\n",
    "        normal = shifted / np.max(shifted)\n",
    "        return normal\n",
    "    X = (normalize(points_xyz[:, 0]) * (width-1)).astype(int)\n",
    "    Y = (normalize(points_xyz[:, 1]) * (height-1)).astype(int)\n",
    "\n",
    "    # Assign scaled intensity values to the corresponding pixel in the histogram\n",
    "    lidar_image_array[Y, X] = 255\n",
    "\n",
    "    # Display the processed image using Pygame\n",
    "    cv2.imshow(window_name, lidar_image_array)\n",
    "\n",
    "def save_semantic_lidar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    lidar_data = np.array([(detection.point.x, detection.point.y, detection.point.z, int(detection.object_tag)) for detection in raw_data])\n",
    "    lidar_data = filter_semantic_lidar_readings(lidar_data)\n",
    "    points = lidar_data[:, :3]\n",
    "    # Create an Open3D point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # Save the point cloud to a .ply file\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    o3d.io.write_point_cloud(f\"{target_directory}/{filename}\", point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATED_DATA_DIRECTORY = \"./generated_data\"\n",
    "delete_all_in_directory(SIMULATED_DATA_DIRECTORY)\n",
    "\n",
    "cv2.namedWindow(\"Press Q to stop simulation\")\n",
    "cv2.imshow(\"Press Q to stop simulation\", np.zeros((1,1)))\n",
    "\n",
    "try:\n",
    "    with CarlaSyncMode(world, sensors, fps=10) as sync_mode:\n",
    "        while True:\n",
    "            simulation_results = sync_mode.tick(timeout=300.0)[1:]\n",
    "            for i in range(len(simulation_results)):\n",
    "                sensor = sensors[i]\n",
    "                sensor_data = simulation_results[i]\n",
    "                sensor_name = sensor_names[i].replace(\"base_link_to_\", \"\")\n",
    "                sensor_type = sensor_types[i]\n",
    "                if (\"camera.rgb\" in sensor_type):\n",
    "                    #visualize_rgb_image(sensor_data, sensor_name, window_size = (480, 270))\n",
    "                    save_rgb_image(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"camera.semantic_segmentation\" in sensor_type):\n",
    "                    #visualize_semantic_image(sensor_data, sensor_name, window_size = (480, 270))\n",
    "                    save_semantic_image(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                    save_semantic_image_mask(sensor_data, f\"generated_data/{sensor_name}/\", masked_colors=[\n",
    "                        SemanticColors.ROADLINE.value, SemanticColors.ROAD.value, SemanticColors.SIDEWALK.value,\n",
    "                        SemanticColors.GROUND.value, SemanticColors.WATER.value, SemanticColors.TERRAIN.value,\n",
    "                        SemanticColors.SKY.value\n",
    "                    ])\n",
    "                elif (\"sensor.other.radar\" in sensor_type):\n",
    "                    #visualize_radar(sensor_data, sensor_name)\n",
    "                    save_radar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"camera.depth\" in sensor_type):\n",
    "                    #visualize_depth_image(sensor_data, sensor_name, window_size = (480, 270))\n",
    "                    save_depth_image(sensor_data, f\"generated_data/{sensor_name}/\") \n",
    "                elif (\"sensor.lidar.ray_cast_semantic\" in sensor_type):\n",
    "                    #visualize_semantic_lidar(sensor_data, sensor_name)\n",
    "                    save_semantic_lidar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"sensor.lidar\" in sensor_type):\n",
    "                    #visualize_lidar(sensor_data, sensor_name)\n",
    "                    save_lidar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                save_sensor_position(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "            for vehicle in vehicles:\n",
    "                position = map.get_waypoint(vehicle.get_transform().location)\n",
    "                next_postition = random.choice(position.next(1.5))\n",
    "                vehicle.set_transform(next_postition.transform)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    for sensor in sensors:\n",
    "        sensor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
